---
title: Insert title here
key: 136a792db4290c0987ebbd4af679b4ee

---
## Lesson 2.1: The logistic function and logistic regression

```yaml
type: "TitleSlide"
key: "d97da616fc"
```

`@lower_third`

name: Matt Baucum
title: Data Scientist, M.A.


`@script`
Now that we've learned some of the core concepts of linear regression, we're going to take a look at logistic regression--another kind of regression that's especially helpful when we have a binary response variable.


---
## Binary Response Variables

```yaml
type: "TwoColumns"
key: "5d2e77d539"
```

`@part1`
Survey of satisfaction with mobile app {{1}}

- x: Satisfaction (0-7 scale) {{2}}

- y: Recommend to friend (1=Yes, 0=No) {{3}}


`@part2`



`@script`
Let's imagine we have a dataset of users' satisfaction with an app we've developed, on a 1-7 scale. And as part of this survey, we also asked participants whether they would recommend this app to a friend--which was phrased as a yes-no question. So we have a continuous predictor variable, and a binary response variable that can only take on two values. And we want to see whether user satisfaction predicts whether they would recommend the app to a friend. Spoiler alert, I imagine that would be the case.


---
## Binary Response Variables

```yaml
type: "TwoColumns"
key: "31f4eabfb6"
disable_transition: true
```

`@part1`
Survey of satisfaction with mobile app

- x: Satisfaction (0-7 scale)

- y: Recommend to friend (1=Yes, 0=No)


`@part2`
![](http://i67.tinypic.com/2i79s79.jpg)


`@script`
Here's one way to graph those variables--for each user, we simply plot their satisfaction score on the x axis, and plot their point at y=0 or y=1 depending on whether they could recommend our app to a friend. This dataset won't play very well with linear regression, and here's why.


---
## Binary Response Variables

```yaml
type: "TwoColumns"
key: "a535b27fd6"
disable_transition: true
```

`@part1`
Survey of satisfaction with mobile app

- x: Satisfaction (1-7 scale)

- y: Recommend to friend (1=Yes, 0=No)


`@part2`
![](http://i65.tinypic.com/r08eu8.jpg)


`@script`
If you plotted a line of best fit through the data, you see that a linear model goes outside the bounds of my response variable. Y can only take on the values 0 or 1, and the line of best fit will inevitably go above 1 or below 0 for some values of x.


---
## Logistic Regression to the Rescue

```yaml
type: "FullSlide"
key: "2db3cbd323"
```

`@part1`
We need a model that:
1. Is linear {{1}}
2. Makes sense for a binary response variable {{2}}

Logistic regression: {{3}}
1. Creates a linear model of predictors: _u=b0+b1*Satisfaction_ {{4}}
2. Uses _logistic_ function _(1/1+exp(-u))_ to transform output to (0,1) {{5}}
3. Treat output as Pr(Y=1): {{6}}


`@script`
So we'd like to keep our model linear, but in a way that makes sense for a response variable that's restricted to 0 or 1. So what we do is we try to predict the probability that our response variable takes on a value of 1.

To do that, we still create a linear model with our predictors--though as you saw from the last graph, the output of that linear model could take on any value. So we use what's called a _logistic function_ to transform that unbounded output to the (0,1) interval. You don't need to memorize this formula--basically, it's just taking some value u, which could be anything, and forcing the output to be between 0 and 1. As u becomes more and more negative, this function output gets closer to zero. As u becomes more positive, the output gets closer to 1. And we treat that output as the _probability_ of our response variable occurring.


---
## Logistic Regression to the Rescue

```yaml
type: "TwoColumns"
key: "f6f7977b49"
disable_transition: false
```

`@part1`
![](http://i67.tinypic.com/2i79s79.jpg)


`@part2`



`@script`
And here's what the output of a logistic regression would look like. On the left, we have our plot of our data, just like before.


---
## Logistic Regression to the Rescue

```yaml
type: "TwoColumns"
key: "f071bb12a4"
```

`@part1`
![](http://i67.tinypic.com/2i79s79.jpg)


`@part2`
![](http://i67.tinypic.com/5pinhj.jpg)


`@script`
And here's what the output of a logisitc regression model would look like. Unlike just forcing a linear regression onto this data, the logistic function predicts a probability value between 0 and 1 for every set of predictor values. The shape of that best fut curve is actually the shape of the logistic function itself--hence, why we call this method logistic regression.


---
## Practice!

```yaml
type: "FinalSlide"
key: "86fb5a71df"
```

`@script`
Now, we'll do a couple of exercises where you'll practice identifying whether a variable is a good candidate for logistic regression, and make some probability predictions from a logistic regression model.

